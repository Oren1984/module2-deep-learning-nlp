# 📄 פרויקט 2 — NLP קלאסי (Pipeline סטטיסטי)

##  מטרת הפרויקט
סיווג הודעות SMS לשתי מחלקות:
- **HAM (0)** — הודעות לגיטימיות  
- **SPAM (1)** — הודעות זבל / פרסומות / פישינג  

הפרויקט מדגים Pipeline קלאסי של NLP המבוסס על הנדסת תכונות סטטיסטית ומודלים לינאריים.

---

## 📊 הדאטה
- **שם הדאטהסט:** SMS Spam Collection  
- **מספר דגימות:** 5,572  
- **התפלגות מחלקות:**
  - Ham: 4,825  
  - Spam: 747  
- **שיעור ספאם:** כ־13.4%

### סטטיסטיקות טקסט (EDA קצר)
- אורך הודעה ממוצע: ~15.5 מילים  
- אורך חציוני: 12 מילים  
- הודעות קצרות, לא פורמליות ורועשות — אידיאלי ל־NLP קלאסי

---

## 🧠 הגישה (NLP קלאסי)
הפרויקט נמנע במכוון מ־Deep Learning ומתמקד ב־Baseline חזק, מהיר וניתן לפרשנות.

### הנדסת תכונות
- **TF-IDF**
- ייצוג Bag-of-Words  
- הסרת מילות עצירה  
- בדיקה אופציונלית של n-grams  

### מודלים
- **Baseline:** TF-IDF + Naive Bayes  
- **Final:** TF-IDF + Linear SVM (LinearSVC)

---

## 🧪 שלבי ה־Pipeline
1. טעינת נתונים ונרמול  
2. EDA מהיר  
3. ניקוי ועיבוד טקסט  
4. אימון מודל בסיס  
5. אימון מודל מתקדם  
6. הערכה על סט בדיקה  
7. רגולריזציה וכוונון  
8. Inference  
9. יצירת דוח מסכם  

---

## 📈 תוצאות (Test Set)

| מדד | ערך |
|----|-----|
| Accuracy | ~0.986 |
| Precision | ~0.993 |
| Recall | ~0.899 |
| F1-score | ~0.944 |

### פרשנות
- Accuracy גבוה מאוד  
- Recall נמוך מ־Precision → המודל שמרני  
- חלק מהודעות הספאם עדיין מפוספסות

---

## 📊 מטריצת בלבול
- הפרדה ברורה בין Ham ל־Spam  
- רוב השגיאות הן False Negatives (Spam → Ham)

---

## 🧠 תובנות מרכזיות
- NLP קלאסי יעיל מאוד לטקסטים קצרים  
- TF-IDF הוא Baseline חזק  
- Linear SVM עדיף על Naive Bayes  
- Accuracy לבדו אינו מדד מספיק

---

✔️ סטטוס: הפרויקט הושלם ורץ E2E
